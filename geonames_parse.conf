input {
  file {
    path => "c:/apps/logstash/prototype1.log"
    codec => json
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "prototype_data"
  }

  file {
    path => "c:/apps/logstash/cities15000.txt"
    codec => plain
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "geonames"
  }  
}

filter {
  if [type] == "geonames" {
    mutate {
      gsub => ["message", "\"", "?"]
    }
    csv {
      columns => ["geonameid", "name", "asciiname", "alternatenames", "latitude", "longitude", "feature_class", "feature_code", "country_code", "cc2", "admin1_code", "admin2_code", "admin3_code", "admin4_code", "population", "elevation", "dem", "timezone", "mod_date"]
      separator => "	"
        add_tag => [ "geoname" ]
      } 

    mutate {
      gsub => ["name", "\?", '"',   "asciiname", "\?", '"',     "alternatenames", "\?", '"']
    }

    mutate {
      split => ["alternatenames", ","]
    }

    if "geoname" in [tags] {
      mutate {
        remove_field => [ "message" ]
      }
    } else {
      mutate {
        add_tag => ["geoname_parse_failure"]
      }
    }
  }
}

output {  
  if [type] == "prototype_data" {
    elasticsearch {
      host => localhost
      protocol => "http"
    }
  }
  
  if [type] == "geonames" {
    if "geoname" in [tags] {
      file {
        flush_interval => 0
        path => "c:/apps/logstash/geonames.log"
      }
    } else {
      file {
        flush_interval => 0
        path => "c:/apps/logstash/geonames_failed.log"
      }
      stdout {
        codec => rubydebug
      }  
    }  
  }
}


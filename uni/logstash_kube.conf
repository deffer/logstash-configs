input {
  beats {
    #Used for filebeat input
    port => 5044
  }
  tcp {
    #Used for JournalD input
    port => 5045
    codec => line
    add_field => { "source_type" => "journald" }
    add_field => { "source" => "/var/log/messages/journald.log" }
  }
}


filter {

#Application specific filters to get input into a standardised format

  if [source_type] == "mule_app" {
    grok {
      break_on_match => false
      patterns_dir => "./patterns"
      match => [ "message", "%{TIMESTAMP_ISO8601:loggedtime} \[%{DATA:thread}\] %{LOGLEVEL:level} %{DATA:class} - %{GREEDYDATA:message}" ]
      overwrite => [ "message" ]
      match => [ "source", "%{GREEDYDATA}/%{GREEDYDATA:filename}.log" ]
      match => [ "node_name", "%{WORD:host_temp}" ]
    }
    mutate {
      replace => { "app_env" => "%{env_name}" }
      replace => { "app_name" => "%{filename}" }         
      remove_field => [ "env_name" ]
      remove_tag => [ "beats_input_codec_plain_applied" ]
    }

  } else if [source_type] == "mule_runtime" {
    grok {
      patterns_dir => "./patterns"
      match => { "message" => "%{LOGLEVEL:level}( )+%{TIMESTAMP_ISO8601:loggedtime} \[%{DATA:thread}\] %{DATA:class}: %{GREEDYDATA:description}" }
    }
  } else if [source_type] == "kafka" {
    grok {
      patterns_dir => "./patterns"
      match => { "message" => "\[%{TIMESTAMP_ISO8601:loggedtime}\] %{LOGLEVEL:level} (\[%{DATA:thread}\]:)? %{GREEDYDATA:description} (\(%{DATA:class}\))?" }
    }
  } else if [source_type] == "zookeeper" {
    grok {
      patterns_dir => "./patterns"
      match => { "message" => "%{TIMESTAMP_ISO8601:loggedtime} \[%{DATA:class}\] - %{LOGLEVEL:level}  \[%{DATA:thread}\] - %{GREEDYDATA:description}" }
    }
  } else if [source_type] == "jmx" {
      # multiline message passed to logstash as single message. 1 metric per line. 
	  #  if metrics are from zookeper, message will contain all info about all cluster members,
	  #   so we also want to tag "own" metrics as "SELF"
      mutate {
        gsub => ["message","\[(.*?)\]",""]
      }
      ruby {
        code => 
      '
      hash = {}
      integer = /^[0-9]*$/m
      float = /^[-+0-9]*[.]?[0-9]*[eE-]*[0-9]*$/m
      zook = /zookeeper\.\w+\.(?:Leader|Follower)\.(\w+)/
      lines = event["message"].lstrip.split("\n")
      for line in lines 
        keyval = line.split(" ")
        keyname = keyval.first.gsub(".","-")
        if integer.match(keyval.last)
          hash[keyname] = keyval.last.to_i
        elsif float.match(keyval.last)
          hash[keyname] = keyval.last.to_f
        else 
          hash[keyname] = keyval.last
        end
        zook.match(keyval.first){|m|  hash["zookeper-SELF-#{m[1]}"] = hash[keyname] } 
      end
      event["jmxstats"] = hash
      '
   }
  } else if [source_type] == "journald" {
    grok {
	  break_on_match => false
	  overwrite => [ "description" ]
      match => { "message" => "%{TIMESTAMP_ISO8601:loggedtime} %{HOSTNAME:node_name} %{GREEDYDATA:class}\[%{BASE10NUM:type}\]: %{GREEDYDATA:description}" }	  
      match => { "description" => "%{WORD:level} %{GREEDYDATA:misc1}   %{BASE10NUM:type} %{GREEDYDATA:thread}\] %{GREEDYDATA:description}" }	  
    }
  }

#Generic field updates that apply to all inputs - get input ready to ship to ELK
  
  if [source_type] != "mule_app" {
    grok {
      break_on_match => false
      match => [ "source", "%{GREEDYDATA}/%{GREEDYDATA:filename}.log" ]
      match => [ "node_name", "%{WORD:host_temp}" ]
    }
  }
  grok {
    match => ["node_name", "%{GREEDYDATA}(?<host_env>(?:dev|tst|prd))%{NUMBER}" ]
  }
  if [host_env] == "dev" {
    # both dev and test kube namespaces are running in TEST kube environment
    mutate {
       replace => {"host_env" => "tst"}
    }
  }
  date {
     match => [ "loggedtime", "ISO8601" ]
  }
  mutate {
    replace => { "[beat][hostname]" => "%{node_name}" }
    replace => { "host" => "%{host_temp}" }
    # do not remove message. in case of _grokparsefailure we dont want to lose the message
    # also mule_app will override message with extracted description
    remove_field => [ "type", "path",  "loggedtime", "node_name", "host_temp" ]
  }
}

output {

#Output for debugging - JSON - uncomment for testing
#  file {
#    path => "/var/log/logstash/lsout.log"
#    codec => json_lines
#  }

#Output for debugging - RubyDebug - uncomment for testing
 # file {
  #  path => "/var/log/logstash/lsoutr.log"
  #  codec => rubydebug
  #}

#Elastic Output
  elasticsearch { 
    #hosts => ["elastic.kube-system.svc.kube.local:9200"] 
     hosts => ["host-f5vip.auckland.ac.nz:80"]
  }

}
